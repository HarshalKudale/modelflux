# LLM Hub - MVP Architecture Blueprint

> A cross-platform React Native app for chatting with multiple LLM providers (OpenAI, Anthropic, Ollama) with local conversation storage.

---

## ğŸ“ High-Level Architecture

```mermaid
graph TB
    subgraph UI Layer
        Screens[Screens]
        Components[Components]
    end

    subgraph State Layer
        ConversationStore[Conversation Store]
        LLMStore[LLM Config Store]
        SettingsStore[Settings Store]
    end

    subgraph Core Layer
        subgraph LLM Module
            LLMClient[LLM Client Interface]
            OpenAIProvider[OpenAI Provider]
            AnthropicProvider[Anthropic Provider]
            OllamaProvider[Ollama Provider]
        end

        subgraph Storage Module
            ConversationRepo[Conversation Repository]
            MessageRepo[Message Repository]
            LLMConfigRepo[LLM Config Repository]
            SettingsRepo[Settings Repository]
            StorageAdapter[Storage Adapter]
        end

        subgraph Sync Module
            SyncStub[Sync Service - Stub]
        end
    end

    subgraph Platform
        AsyncStorage[AsyncStorage / localStorage]
    end

    Screens --> Components
    Screens --> ConversationStore
    Screens --> LLMStore
    Screens --> SettingsStore

    ConversationStore --> ConversationRepo
    ConversationStore --> MessageRepo
    ConversationStore --> LLMClient

    LLMStore --> LLMConfigRepo
    SettingsStore --> SettingsRepo

    ConversationRepo --> StorageAdapter
    MessageRepo --> StorageAdapter
    LLMConfigRepo --> StorageAdapter
    SettingsRepo --> StorageAdapter

    StorageAdapter --> AsyncStorage

    LLMClient --> OpenAIProvider
    LLMClient --> AnthropicProvider
    LLMClient --> OllamaProvider
```

---

## ğŸ”‘ Core Design Principles

| Principle | Description |
|-----------|-------------|
| **Provider Agnostic** | UI never directly communicates with LLM APIs; all traffic goes through `LLMClient` interface |
| **Repository Pattern** | All data access abstracted via repository interfaces; storage implementation swappable |
| **Platform Abstraction** | Storage adapter handles platform differences (AsyncStorage on mobile, localStorage on web) |
| **Offline First** | All data stored locally; no network required except for LLM API calls |
| **Minimal State** | Zustand stores for reactive state; repositories for persistence |

---

## ğŸ”„ Core Data Flow

### Chat Message Flow

```mermaid
sequenceDiagram
    participant User
    participant ChatScreen
    participant ConversationStore
    participant LLMClient
    participant Provider
    participant MessageRepo

    User->>ChatScreen: Types message & sends
    ChatScreen->>ConversationStore: sendMessage(content)
    ConversationStore->>MessageRepo: save(userMessage)
    ConversationStore->>LLMClient: sendMessage(config, messages)
    LLMClient->>Provider: API call (OpenAI/Anthropic/Ollama)
    Provider-->>LLMClient: Response/Stream
    LLMClient-->>ConversationStore: LLMResponse
    ConversationStore->>MessageRepo: save(assistantMessage)
    ConversationStore-->>ChatScreen: Update messages
    ChatScreen-->>User: Display response
```

### LLM Provider Selection Flow

```mermaid
sequenceDiagram
    participant User
    participant ChatHeader
    participant ConversationStore
    participant LLMConfigRepo
    participant ConversationRepo

    User->>ChatHeader: Select different LLM/Model
    ChatHeader->>ConversationStore: setActiveLLM(llmId, model)
    ConversationStore->>ConversationRepo: updateConversation({activeLLMId})
    ConversationStore-->>ChatHeader: Updated state
    Note over ChatHeader: Future messages use new LLM
    Note over ConversationStore: Past messages retain original llmIdUsed
```

---

## ğŸ“‚ Folder Structure

```
/src
â”œâ”€â”€ /core                          # Business logic layer
â”‚   â”œâ”€â”€ /llm                       # LLM provider abstraction
â”‚   â”‚   â”œâ”€â”€ LLMClient.ts           # Main client interface & factory
â”‚   â”‚   â”œâ”€â”€ types.ts               # LLM-related TypeScript types
â”‚   â”‚   â””â”€â”€ /providers
â”‚   â”‚       â”œâ”€â”€ BaseProvider.ts    # Abstract base provider
â”‚   â”‚       â”œâ”€â”€ OpenAIProvider.ts
â”‚   â”‚       â”œâ”€â”€ AnthropicProvider.ts
â”‚   â”‚       â”œâ”€â”€ OllamaProvider.ts
â”‚   â”‚       â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ /storage                   # Local storage abstraction
â”‚   â”‚   â”œâ”€â”€ StorageAdapter.ts      # Platform-agnostic storage interface
â”‚   â”‚   â”œâ”€â”€ /repositories
â”‚   â”‚   â”‚   â”œâ”€â”€ ConversationRepository.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageRepository.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ LLMConfigRepository.ts
â”‚   â”‚   â”‚   â””â”€â”€ SettingsRepository.ts
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â””â”€â”€ /sync                      # Future sync capability (stub)
â”‚       â””â”€â”€ SyncService.stub.ts
â”‚
â”œâ”€â”€ /state                         # State management (Zustand)
â”‚   â”œâ”€â”€ conversationStore.ts
â”‚   â”œâ”€â”€ llmStore.ts
â”‚   â”œâ”€â”€ settingsStore.ts
â”‚   â””â”€â”€ index.ts
â”‚
â”œâ”€â”€ /ui                            # UI layer
â”‚   â”œâ”€â”€ /screens
â”‚   â”‚   â”œâ”€â”€ ChatScreen.tsx
â”‚   â”‚   â”œâ”€â”€ ConversationListScreen.tsx
â”‚   â”‚   â”œâ”€â”€ SettingsScreen.tsx
â”‚   â”‚   â”œâ”€â”€ LLMManagementScreen.tsx
â”‚   â”‚   â””â”€â”€ LLMEditorScreen.tsx
â”‚   â”‚
â”‚   â”œâ”€â”€ /components
â”‚   â”‚   â”œâ”€â”€ /chat
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageBubble.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageInput.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatHeader.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ModelSelector.tsx
â”‚   â”‚   â”œâ”€â”€ /sidebar
â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ConversationItem.tsx
â”‚   â”‚   â”‚   â””â”€â”€ UserInfo.tsx
â”‚   â”‚   â”œâ”€â”€ /settings
â”‚   â”‚   â”‚   â”œâ”€â”€ LLMConfigCard.tsx
â”‚   â”‚   â”‚   â””â”€â”€ SettingsSection.tsx
â”‚   â”‚   â””â”€â”€ /common
â”‚   â”‚       â”œâ”€â”€ Button.tsx
â”‚   â”‚       â”œâ”€â”€ Input.tsx
â”‚   â”‚       â””â”€â”€ Dropdown.tsx
â”‚   â”‚
â”‚   â””â”€â”€ /navigation
â”‚       â”œâ”€â”€ AppNavigator.tsx
â”‚       â””â”€â”€ types.ts
â”‚
â”œâ”€â”€ /config                        # App configuration
â”‚   â”œâ”€â”€ constants.ts               # App-wide constants
â”‚   â”œâ”€â”€ providerPresets.ts         # Default LLM provider configs
â”‚   â””â”€â”€ theme.ts                   # Theme configuration
â”‚
â””â”€â”€ App.tsx                        # Entry point
```

---

## ğŸš« MVP Boundaries

### âœ… In Scope

| Feature | Description |
|---------|-------------|
| Multi-provider LLM support | OpenAI, Anthropic, Ollama |
| Local conversation storage | All data persisted on device |
| Cross-platform | Android, iOS, Web |
| Mid-conversation LLM switching | Change provider without losing history |
| Model selection | Per-conversation model configuration |
| Settings management | Theme, streaming toggle, LLM config CRUD |
| Data export/import | JSON format for conversations |
| Image output display | Show generated images from models like DALL-E |

### âŒ Explicit Non-Goals

| Feature | Reason |
|---------|--------|
| Authentication | No user accounts in MVP |
| Cloud sync | Local-only storage |
| Prompt templates | Beyond chat scope |
| Function calling / Tools | Advanced feature |
| Image/Voice input | Text input only (output images supported) |
| Plugins | Extensibility deferred |
| Multiple chat windows | Single conversation focus |

---

## ğŸ”§ Technology Stack

| Layer | Technology | Rationale |
|-------|------------|-----------|
| **Framework** | React Native + Expo | Cross-platform, fast iteration |
| **Web Support** | React Native Web | Single codebase for web |
| **State Management** | Zustand | Lightweight, TypeScript-friendly |
| **Storage** | AsyncStorage + localStorage | Platform-native, works offline |
| **Navigation** | React Navigation | Industry standard for RN |
| **HTTP Client** | fetch API | Built-in, sufficient for LLM APIs |
| **Streaming** | EventSource / fetch streams | SSE for streaming responses |

---

## ğŸ“ Next Steps

Refer to the following documents for detailed specifications:

1. [Data Models](./DATA_MODELS.md) - TypeScript interfaces
2. [Service Interfaces](./SERVICE_INTERFACES.md) - Core service contracts
3. [Component Breakdown](./COMPONENT_BREAKDOWN.md) - UI responsibility matrix
